Всем привет
меня зовут Дима, сейчас я работаю дэвэлопером на напроекте Fidor, 
и сегодня мы с вами поговорим про перформанс, и основные ошибки при разработке связанные с перформансом

Данный спич был изначально сформирован как своеобразный "крик души", в результате моей работы на нескольких последних проектах
То, о чём я сегодня буду говорить, многие, 90% из вас, это всё слышали и знают, 
Но иногда, когда смотришь кем-то уже написаный код, понимаешь что про некоторые моменты мы часто забываем к сожалению,
поэтому прошу не относиться к данному докладу свысока :)

Будет много примеров на руби но на самом деле всё о чём я буду рассказывать актуально и для других языков

Начну я с самых простых и очевидных тем, и уже по ходу будем углубляться в более интересные вещи, а самое интересное будет в конце.
Что ж, начнём

1. Пагинация
Представьте ситуацию : вы пилите новую систему для заказчика, всё локльно и на тестинге было хорошо, всё отлично и быстро работало,
потом вы ушли в прод, смигрировали на новую систему всех пользователей ... и на некоторых страницах получили вот такое: (слайд)
Почему это произошло? правильно. у вас на тэстинге было на какой-то странице 20 сущностей, а на проде их 2_000, пагинации у вас нет, поэтому страница рендерится минуты 3, а NGINX стоит с дэфолтным таймаутом в минуту.
Чтобы такого не случалось - на всех страницах где вы ожидаете большое кол-во сущностей нужно сразу прикручивать пагинацию
Это так же актуально если вы предоставляете какой-то эндпоинт
для всех языков есть готовые либы которые делают процесс пагинации унифицированным, не нужно изобретать свой велосипед, просто заинклюдили одну строчку (или отнаследовались, всё зависит от вашего языка) и готово
2. Излишняя (тупая) работа:
2.1 - N+1 запросы
к сожалению эра ОРМок не только значительно упростила жизнь программистам, но и привела к тому что некоторые не разбираются как ОРМки работают под капотом
вот наглядный пример с https://guides.rubyonrails.org/active_record_querying.html#eager-loading-associations

это не кажется очень страшным.. по началу.., но в итоге всё заканчивается вот таким:

```ruby
hash = {}
BulkUpload::File.all.each {|f| hash[f.id] = f.file_content.content.length}
```

вот ещё пример:
http://tomdallimore.com/blog/includes-vs-joins-in-rails-when-and-where/, лог сервера при запросе:
Вот было (первый слайд) - 265 миллисекунд (это четверть секунды)
а вот стало: (второй слайд) - 2.8 миллисекунды
ускорение - почти в 100 раз
на самом деле эти картинки я взял из интернетов и лишь догадываюсь каким образом автор поменял запрос
но это не важно, важно понимать, что каждый раз когда вы в логах видите вот такое : (отмотать на предыдущий слайд) - ЭТО НЕ НОРМАЛЬНО,
но на каком бы языке вы ни писали - у вас скорей всего есть ОРМка которая позволяет дописав 20 символов это исправить

Как за этим следить? я не искал тулзы для других языков, но для руби есть например Bullet. (скрин страницы с гитхаба)
Его можно сконфигурировать очень тонко (тут скриншот опций), он может и просто выдавать ворнинги, и даже валить эксепшены, нотифаить эйрбрэйк, слак и кучу других сервисов
Для других технологий я уверен тоже есть такие тулзы, просто погуглите



2.2 отсутствие кэширования там где оно нужно
Кэширование - вообще отдельная тема и тут есть тысяча различных уровней на которых можно что-либо кэшировать
на каком уровне кэшировать данные - вы должны сами определить в зависимости от конкретной ситуации, но эт овсегда приносит профит
2.2.1 кэширование на уровне сервиса (привести пример подсчёта N-го числа фибоначчи), который вы в участке кода создали, 10/100/500 раз заюзали и выкинули - вы из этого куска кода вышли и больше кэша нет, ибо GC сожрал сервис и все данные
2.2.2 кэширвоание на время всего реквэста - в рубях например выглядит так (гем RequestStore) - суть в том что встраивается дополнительный middleware, котоырй начинает работать по приходу реквэста, и заканчивает по отдаче респонса
2.2.3 Кэширование на определённое время (час/день/год) - Redis one love (http://rusrails.ru/caching-with-rails-an-overview#nizkourovnevoe-keshirovanie)
2.2.4 Conditional GET (HTTP_IF_NONE_MATCH, HTTP_IF_MODIFIED_SINCE) - http://rusrails.ru/caching-with-rails-an-overview#podderzhka-get-s-usloviem-conditional-get
2.3 - и последний пункт в разделе "ненужная работа" - проблемы с логикой. пример:
на моём текущем проекте пользователи могут грузить файлы в которых умещается до 50.000 денежных трансферов различным получателям, на определённом этапе нам нужно отвалидировать что любой из этих трансферов имеет сумму меньшую чем определённый лимит пользователя, иначе нужно выдать ошибку "как минимум один трансфер не влазит в лимит"
лимит у нас хранится на другом микросервисе
Как нужно было сделать:
выбрать наибольший amount из всех трнсферов и отправить его на другой микросервис, спросить "проходит ли он?", если он проходит - все остальные точно проходят, если нет - мы кидаем ошибку
как вы думаете как было сделано?
да-да, вы правильно догадались, мы делали 50000 запросов к другому сервису.
Исправление трёх строчек кода в том месте дало просто бешеный буст, и исправило REQUEST_TIMEOUT для больших файлов

3. предварительная работа:
пример: представьте что вы аггрегируете какие-нибудь данные пользователей (например я работал на проекте где мы собирали данные от датчиков солнечных батарей), а потом они заходят к вам и скачивают отчёты
и вот заказчики жалуются что отчёты долго грузятся.
вы проанализировали запросы по репортам и заметили что каждый месяц в первых числах заказчики скачивают отчёт за прошлый месяц. в таком случае вы можете просто написать крон джобу, которая данный отчёт будет в час ночи первого числа каждого месяца генерировать и складывать в редис, со сроком жизни в 10 дней например (т.е. предыдущий пункт, просто мы заранее ложим в кэш и заказчикам не нужно ждать)

4. Слишком долгие запросы к базе (применительно к реляционным БД, в нереляционных мало опыта):
бывает так что вы уже вроде бы всё кэшируете, убрали N+1 и т.д., но видите что на данной странице вам нужно построить репорт, используя здоровенную кучу данных.
предположим что репорты юзеры хотят всё время разные, с разным набором колонок, за разные временные интервалы - кэширование не поможет
Тут можно конечно запихнуть это всё в асинхронную джобу, которая юзеру пришлёт данные на емэйл через пару минут, но если вы видите что у вас SELECT выполняется 2 минуты - это повод посмотреть что не так
Тут стоит ещё отдельно упомянуть, что важно для каждой цели использовать нужный тип БД,  и естественно есть ситуации где вам придётся заюзать какое-нибудь NOSQL решение, но по моему опыту, зачастую люди просто не умеют правильно готовить реляционки, так что я советую сначала убедиться что вы правильно используете вашу реляционку, и уж если это не помогло - только тогда плыть в сторону исследования альтернативных вариантов
4.1 EXPLAIN ANALYZE и отсутствие индексов - !!! тут погуглить какие типы запросов в БД бывают (нашел: https://use-the-index-luke.com/sql/explain-plan/postgresql/operations), перечислить их, с буквально 2 словами описания про каждый, привести наглядный пример с огромным бустом по производительности
Данные вещи на самом деле релевантны не только для реляционных БД

5. Как понять, с чем бороться а что не стоит затраченных усилий

5.1 нужно ВСЕГДА тестировать свой код на объёме данных, сопоставимом с объёмом данных ожидающихся на проде.
5.1.1 - БД: нужно нагенерировать такой объём данных как локально так и для тестового окружения на самом деле не составляет большой проблемы - есть готовые тулзы которые генерят похожие на реальные имена, фамилии, адреса и т.д., нужно лишь написать скрипт который забьёт вам базу лишними данными - это сделает сами запросы медленней, а ещё покажет где вы забыли про пагинацию :)
5.1.2 - загружаемые данные: дэвелопер который написал код отправляющий 50000 запросов к другому микросервису скорее всего протестировал его локально с файлом имеющим один-два трансфера. так делать не надо, если в файле может быть до 50к записей, нагенерьте хотя бы 5к
5.2 профайлинг!
5.2.1 преждевременная оптимизация
говорят, что преждевременная оптимизация - зло
на самом деле я считаю что достаточно опытный разработчик способен многие нужные вещи, такие как "куда навесить индексы", определить заранее,
но тут стоит во-первых руководствоваться принципом паретто: 80% оптимизации можно сделать затратив 20% усилий
не стоит перебарщивать, оптимизацию нужно делать только если вы на 100% уверены что она там пригодится
если же нет - лучше не тратить драгоценное время на преждевременную оптимизацию, которая в будующем может оказаться не стоившей затраченных усилий

если же вы c командой вроде писали-писали проект, а потом оказалось что он тормозит - ни в коем случае не стоит с пеной у рта кричать "да я знаю в чём тут дело, ща я всё заоптимизирую"
потому что на самом деле в большинстве случаев окажется что вы были не правы
для того чтобы проводить оптимизацию именно того что нужно, нужен профайлинг

5.2.2 Флэймграф и компания
профайлинг может быть как внешний и серьёзный (и дорогой :( ), а-ля NewRelic, 
так и опенсорсный, в разных языках есть разные тулзы, мне понравился Flamegraph
http://www.brendangregg.com/flamegraphs.html
он хоть и простой и мне кажется недостаточно популярный, но для фанатов идти в ногу за большими корпорациями .. вообще не всегда то что подходит большой корпорации подойдёт вашему проекту, но если вы всё же ведётесь на громкие названия - ребята из нэтфликса и яндекса например юзают его и говорят что очень помогает
как он работает и в чём особенность
вы оборачиваете какой-то код в flamegraph, и он генерирует вам примерно такую картинку
!!(объяснить картинку на простом примере)
к чему это в итоге вам может привести:
(найти примеры с реальных проектов, показать до и после)

flamegraph для разных языков:
- оригинальная тулза писалась для профайлинга C++
- есть реализация для Руби , с ней связана правда забавная история :(про флэймграф и руби-релизацию я узнал года 2 назад на rubyconference.by, рассказывал крутой чувак из топтала, в результате когда я попробовал эту реализацию - оказалось что она работает абсолютно не так как нужно, когда я написал письмо этому челу из топтала и спросил "чел, ты же говорил что крутая вещь, а рубишная реализация чото не работает" - получил ответ "ну, я просто слышал про флэймграф от других чуваков, почитал, мне понравилось, я загуглил что есть руби реализация и сделал доклад")
так что не нужно слепо слушать модных дядек на конференциях, иногда они халтурят.
кончилось это всё тем что я просто пару строк подправил в рубишной реализации и мой форк работает, если кто-либо из рубистов заинтересован - вы можете пингануть меня, я кину ссылку
(или вы можете сами разобраться что там работает не так и как это зафиксить, потратите час времени, поменяете 5 строк кода, зато точно будете уверены что понимаете как это работает)
- для питона, я загуглил, тоже есть реализация: https://github.com/uber/pyflame (на этом моменте вы должны вспомнить что я скорей всего тоже схалтурил и не проверял насколько хорошо она работает)

для вашего языка скорее всего есть если не флэймграф то какая-нибудь другая тулза для профилирования
